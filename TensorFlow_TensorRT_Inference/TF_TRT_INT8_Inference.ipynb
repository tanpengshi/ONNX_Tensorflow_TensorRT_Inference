{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet  import preprocess_input\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1249 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:46<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    directory='./CNN_Transfer_Learning_for_Cats_versus_Dogs/test',\n",
    "    target_size=(150, 150), \n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    seed=21\n",
    ")\n",
    "\n",
    "X_test, y_test = next(test_dataset)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_dataset)-1)): \n",
    "    img, label = next(test_dataset)\n",
    "    X_test = np.append(X_test, img, axis=0)\n",
    "    y_test = np.append(y_test, label, axis=0)\n",
    "    \n",
    "X_test_sample = X_test[:32]\n",
    "y_test_sample = y_test[:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:04:57.761638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:57.783464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:57.785288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:57.786285: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-17 11:04:57.788630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:57.790156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:57.791422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:58.382142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:58.383686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:58.383699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:04:58.385205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:04:58.385827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference with TensorFlow TensorRT INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "batched_input = np.zeros((batch_size, 150, 150, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_dog = './CNN_Transfer_Learning_for_Cats_versus_Dogs/train/Dog'\n",
    "img_path_cat = './CNN_Transfer_Learning_for_Cats_versus_Dogs/train/Cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dog_images = np.random.choice(list(paths.list_images(img_path_dog)),4)\n",
    "cat_images = np.random.choice(list(paths.list_images(img_path_cat)),4)\n",
    "\n",
    "all_images = np.concatenate([dog_images,cat_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,img_path in enumerate(all_images):\n",
    "    img = load_img(img_path, target_size=(150, 150))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    batched_input[index, :] = x\n",
    "    \n",
    "batched_input = tf.constant(batched_input)\n",
    "\n",
    "def calibration_input_fn():\n",
    "    yield (batched_input, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 2, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:05:05.667273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.667327: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-10-17 11:05:05.667872: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-10-17 11:05:05.671309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.672771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.674268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.675890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.675900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:05:05.677148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:05.677178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-10-17 11:05:05.699178: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1232 nodes (902), 1899 edges (1569), time = 12.229ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n",
      "\n",
      "2022-10-17 11:05:06.733569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.733623: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-10-17 11:05:06.733717: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-10-17 11:05:06.734994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.736577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.737877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.739656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.739668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:05:06.740995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:05:06.741022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-10-17 11:05:07.135576: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:403] [TF-TRT] not using explicit QDQ mode\n",
      "2022-10-17 11:05:07.262380: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:884] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- NoOp -> 5x\n",
      "\t- Identity -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 7\n",
      "\t- Total nonconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-10-17 11:05:07.281161: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:799] Number of TensorRT candidate segments: 1\n",
      "2022-10-17 11:05:07.387474: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 0 consisting of 251 nodes by TRTEngineOp_0_0.\n",
      "2022-10-17 11:05:07.794206: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 580 nodes (-652), 1247 edges (-652), time = 148.447ms.\n",
      "  layout: Graph size after: 584 nodes (4), 1251 edges (4), time = 122.613ms.\n",
      "  constant_folding: Graph size after: 582 nodes (-2), 1249 edges (-2), time = 37.09ms.\n",
      "  TensorRTOptimizer: Graph size after: 332 nodes (-250), 657 edges (-592), time = 276.317ms.\n",
      "  constant_folding: Graph size after: 332 nodes (0), 657 edges (0), time = 31.104ms.\n",
      "Optimization results for grappler item: TRTEngineOp_0_0_native_segment\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 39.783ms.\n",
      "  layout: Graph size after: 527 nodes (0), 542 edges (0), time = 90.275ms.\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 42.343ms.\n",
      "  TensorRTOptimizer: Graph size after: 527 nodes (0), 542 edges (0), time = 10.843ms.\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 41.461ms.\n",
      "\n",
      "2022-10-17 11:05:09.597064: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:436] TRTEngineOp not using explicit QDQ\n",
      "2022-10-17 11:05:09.601099: I tensorflow/compiler/tf2tensorrt/common/utils.cc:94] Linked TensorRT version: 7.2.2\n",
      "2022-10-17 11:05:09.601247: I tensorflow/compiler/tf2tensorrt/common/utils.cc:96] Loaded TensorRT version: 7.2.2\n",
      "2022-10-17 11:05:16.302656: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-10-17 11:05:17.192831: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-17 11:05:17.654273: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction pruned(resnet50_input) at 0x7F550BCD7820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_params = trt.TrtConversionParams(\n",
    "    precision_mode=trt.TrtPrecisionMode.INT8\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir='my_model',\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "converter.convert(calibration_input_fn=calibration_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_quantized_model_INT8/assets\n"
     ]
    }
   ],
   "source": [
    "converter.save('my_quantized_model_INT8')\n",
    "INT8_model = tf.saved_model.load('my_quantized_model_INT8')\n",
    "func_INT8 = INT8_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:06:34.668869: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:436] TRTEngineOp not using explicit QDQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat     1.0000    0.9375    0.9677        16\n",
      "         Dog     0.9412    1.0000    0.9697        16\n",
      "\n",
      "    accuracy                         0.9688        32\n",
      "   macro avg     0.9706    0.9688    0.9687        32\n",
      "weighted avg     0.9706    0.9688    0.9687        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_proba_INT8 = func_INT8(resnet50_input=X_test_sample)\n",
    "predictions_proba_INT8 = np.array(predictions_proba_INT8['dense_3'])\n",
    "y_predict_INT8 = predictions_proba_INT8.reshape(1,-1)[0]>0.5\n",
    "\n",
    "print(classification_report(y_test_sample, y_predict_INT8,digits=4,target_names=['Cat','Dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat     1.0000    0.9375    0.9677        16\n",
      "         Dog     0.9412    1.0000    0.9697        16\n",
      "\n",
      "    accuracy                         0.9688        32\n",
      "   macro avg     0.9706    0.9688    0.9687        32\n",
      "weighted avg     0.9706    0.9688    0.9687        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_proba = model.predict(X_test_sample)\n",
    "y_predict = predictions_proba.reshape(1,-1)[0]>0.5\n",
    "\n",
    "print(classification_report(y_test_sample, y_predict,digits=4,target_names=['Cat','Dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Probabilities | INT8 Model Probabilities\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.94052213, 0.9364014),\n",
       " (0.042032767, 0.044680867),\n",
       " (0.78132147, 0.7791538),\n",
       " (0.91191137, 0.91949815),\n",
       " (0.43425876, 0.42214724),\n",
       " (0.07807078, 0.07935289),\n",
       " (0.56445783, 0.57606506),\n",
       " (0.90999925, 0.92093205),\n",
       " (0.024335448, 0.031084951),\n",
       " (0.07119049, 0.06828854)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original Model Probabilities | INT8 Model Probabilities\")\n",
    "list(zip(predictions_proba.reshape(1,-1)[0],predictions_proba_INT8.reshape(1,-1)[0]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Inference With TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.09 ms ± 170 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "prediction = func_INT8(resnet50_input=X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Inference Without TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.5 ms ± 1.01 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "prediction = model.predict(X_test_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
