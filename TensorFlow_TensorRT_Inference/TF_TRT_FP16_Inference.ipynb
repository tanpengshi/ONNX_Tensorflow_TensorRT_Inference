{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet  import preprocess_input\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1249 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:45<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    directory='./CNN_Transfer_Learning_for_Cats_versus_Dogs/test',\n",
    "    target_size=(150, 150), \n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    seed=21\n",
    ")\n",
    "\n",
    "X_test, y_test = next(test_dataset)\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_dataset)-1)): \n",
    "    img, label = next(test_dataset)\n",
    "    X_test = np.append(X_test, img, axis=0)\n",
    "    y_test = np.append(y_test, label, axis=0)\n",
    "    \n",
    "X_test_sample = X_test[:32]\n",
    "y_test_sample = y_test[:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:09:36.976872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:36.989114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:36.990321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:36.991652: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-17 11:09:36.994075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:36.995241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:36.996447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:37.469130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:37.470476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:37.470490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:09:37.471695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:37.471750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3384 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference with TensorFlow TensorRT FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 2, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:09:44.570643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.570698: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-10-17 11:09:44.570843: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-10-17 11:09:44.574047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.575797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.577377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.579568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.579582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:09:44.581094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:44.581117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3384 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-10-17 11:09:44.603612: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1232 nodes (902), 1899 edges (1569), time = 12.198ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.01ms.\n",
      "\n",
      "2022-10-17 11:09:45.624787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.624840: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-10-17 11:09:45.624931: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-10-17 11:09:45.626729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.628237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.629437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.631136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.631149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-10-17 11:09:45.632765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-17 11:09:45.632793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3384 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-10-17 11:09:46.044760: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:385] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2022-10-17 11:09:46.044824: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:403] [TF-TRT] not using explicit QDQ mode\n",
      "2022-10-17 11:09:46.184620: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:884] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- NoOp -> 5x\n",
      "\t- Identity -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 7\n",
      "\t- Total nonconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-10-17 11:09:46.203385: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:799] Number of TensorRT candidate segments: 1\n",
      "2022-10-17 11:09:46.319726: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 0 consisting of 251 nodes by TRTEngineOp_0_0.\n",
      "2022-10-17 11:09:46.729961: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 580 nodes (-652), 1247 edges (-652), time = 151.347ms.\n",
      "  layout: Graph size after: 584 nodes (4), 1251 edges (4), time = 137.131ms.\n",
      "  constant_folding: Graph size after: 582 nodes (-2), 1249 edges (-2), time = 37.96ms.\n",
      "  TensorRTOptimizer: Graph size after: 332 nodes (-250), 657 edges (-592), time = 299.946ms.\n",
      "  constant_folding: Graph size after: 332 nodes (0), 657 edges (0), time = 32.621ms.\n",
      "Optimization results for grappler item: TRTEngineOp_0_0_native_segment\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 41.635ms.\n",
      "  layout: Graph size after: 527 nodes (0), 542 edges (0), time = 89.549ms.\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 44.671ms.\n",
      "  TensorRTOptimizer: Graph size after: 527 nodes (0), 542 edges (0), time = 11.243ms.\n",
      "  constant_folding: Graph size after: 527 nodes (0), 542 edges (0), time = 41.796ms.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction pruned(resnet50_input) at 0x7F626A5ABBB0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion_params = trt.TrtConversionParams(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir='my_model',\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find TRTEngineOp_0_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:09:48.188531: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_quantized_model_FP16/assets\n"
     ]
    }
   ],
   "source": [
    "converter.save('my_quantized_model_FP16')\n",
    "FP16_model = tf.saved_model.load('my_quantized_model_FP16')\n",
    "func_FP16 = FP16_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:09:56.983968: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:436] TRTEngineOp not using explicit QDQ\n",
      "2022-10-17 11:09:56.989679: I tensorflow/compiler/tf2tensorrt/common/utils.cc:94] Linked TensorRT version: 7.2.2\n",
      "2022-10-17 11:09:56.989948: I tensorflow/compiler/tf2tensorrt/common/utils.cc:96] Loaded TensorRT version: 7.2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat     1.0000    0.9375    0.9677        16\n",
      "         Dog     0.9412    1.0000    0.9697        16\n",
      "\n",
      "    accuracy                         0.9688        32\n",
      "   macro avg     0.9706    0.9688    0.9687        32\n",
      "weighted avg     0.9706    0.9688    0.9687        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_proba_FP16 = func_FP16(resnet50_input=X_test_sample)\n",
    "predictions_proba_FP16 = np.array(predictions_proba_FP16['dense_3'])\n",
    "y_predict_FP16 = predictions_proba_FP16.reshape(1,-1)[0]>0.5\n",
    "\n",
    "print(classification_report(y_test_sample, y_predict_FP16,digits=4,target_names=['Cat','Dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:10:38.292197: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-10-17 11:10:38.602951: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat     1.0000    0.9375    0.9677        16\n",
      "         Dog     0.9412    1.0000    0.9697        16\n",
      "\n",
      "    accuracy                         0.9688        32\n",
      "   macro avg     0.9706    0.9688    0.9687        32\n",
      "weighted avg     0.9706    0.9688    0.9687        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:10:39.408687: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "predictions_proba = model.predict(X_test_sample)\n",
    "y_predict = predictions_proba.reshape(1,-1)[0]>0.5\n",
    "\n",
    "print(classification_report(y_test_sample, y_predict,digits=4,target_names=['Cat','Dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Probabilities | FP16 Model Probabilities\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.94051033, 0.9404625),\n",
       " (0.042042427, 0.042009056),\n",
       " (0.7816651, 0.7821637),\n",
       " (0.9119552, 0.9119669),\n",
       " (0.4342294, 0.4324828),\n",
       " (0.07813772, 0.078925885),\n",
       " (0.5645249, 0.56481874),\n",
       " (0.90995723, 0.91006696),\n",
       " (0.024338817, 0.02433019),\n",
       " (0.07112902, 0.071073666)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original Model Probabilities | FP16 Model Probabilities\")\n",
    "list(zip(predictions_proba.reshape(1,-1)[0],predictions_proba_FP16.reshape(1,-1)[0]))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Inference With TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ms ± 205 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "prediction = func_FP16(resnet50_input=X_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Inference Without TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4 ms ± 589 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "prediction = model.predict(X_test_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
